This section explains how to automate functional test cases on Connectors.

== Approach Explanation
---
=== Objectives
. Automation test suite integrated to the connector.
. Real sandbox and Mule server used when running the tests.
. Automation test suite maintenance is minimal.
. Outdated automation suite doesn't affect development.

=== Test Creation Criteria
. Launch and shut a Mule instance for each test to ensure isolation from the rest of a suite.
. Use the `setUp()` method to create a test fixture prior to running an actual test.
. Create entities to test each operation.
. Use beans in a Spring file to separate tests from input test data values.
. Make tests flexible enough to support all possible entities and the amount of them (if applicable).
. Only update tests when business logic changes in an operation, or when you modify the operation itself, such as when a signature changes.
. Provide one Mule flow for each operation. Use Java code to glue operations into more complex use cases.
. Clean up tests after each completes, and leave the sandbox in the state prior to running a test.
. Tests should clean up after themselves. Sandbox should be left in the state prior to running the test.
. Test only one thing at a time.

=== Coverage Categories
. *Use a smoke suite* to ensure test preconditions are met for a Regression run.
. *Use a regression suite* to include at least one test case for each operation. Take input on this kind of test from a Mule Message, ensure a test is fully parameterized, and only modify data from the AutomationSpringBeans.xml file.

== mule-connector-test framework
---
=== Objectives
. Provide consistent test suite implementation through the different connectors business models.
. Increase code reusability.
. Improve test case readability by encapsulating complexities.
. Reduce maintenance cost.
. Increase robustness by isolating test suite implementation from Mule classes changes.

=== Concepts
Use cases are built as a sequence of connector operations calls. Prior to running a use case, initialize a TestRunMessage and load the data required by the use case. After you invoke an operation, turn the content of the TestRunMessage into a MuleEvent before an operation consumes the content. Apply asserts to the payload of the operation under the test.

=== Maven Dependency
mule-devkit-parent contains the framework version property (that can, if necessary, be overridden on the connector pom) and its dependency node.

[source,xml]
----
<properties>
   ...
   <connector.test.version>2.0.6</connector.test.version>
</properties>

<!-- Mule Connector Test Framework -->
<dependency>
   <groupId>org.mule.modules</groupId>
   <artifactId>mule-connector-test</artifactId>
   <version>${connector.test.version}</version>
   <scope>test</scope>
</dependency>
----

== Framework and Test Suite Components
---
=== ConnectorTestCase Class
ConnectorTestCase class inherits from *org.mule.tck.junit4.FunctionalTestCase* and wraps FunctionalTestCase methods into methods that both facilitate automating connectors operations use cases and enforce a uniform approach on the construction of test suites. ConnectorTestCase is by *<Connector>TestParent.java* and this class is the parent test class for all of the test cases.

=== ConnectorTestUtils Class
Provides methods for working with _NullPayload_, initializing random test data and also manipulating the date in the Spring file. Also enhances the exception message that displays for more accurate debugging.

=== <Connector>TestParent Class
Extends the ConnectorTestCase class. You can use this class to override default framework configuration settings, add OAuth capabilities, implement helper methods, and store global settings, such as testing run time out rules.

You can define common use cases for the service as class methods to make them available to the rest of the test suite. This makes tests more readable and associates a test with a connector's domain.

All TestCases classes must extend from this TestParent.

=== <OperationName>TestCases Class
*Note:* Do not allow automation tests to be automatically run by Maven because the tests require credentials. Follow the naming conventions for an automation test.

Each operation in the connector has an *<OperationName>TestCases.java* class that contains its related test cases. The sequence of operations called along the *@Before-@Test-@After* cycle make an operation use case.

[source,java]
----
public class <OperationName>TestCases extends <ConnectorName>TestParent {

   // private attributes used as auxiliary fields for storing test run values
   private Integer leadRecordId;

   // creates the test fixture
   @Before
   public void setUp() throws Exception {
     ...
   }

   // returns the sandbox to its original state
   @After
   public void tearDown() throws Exception {
      ...
   }

   // method that invokes the flow of the operation under test and asserts on its payload
   @Category({SmokeTests.class, RegressionTests.class})
   @Test
   public void test<operationName>() {
      try {
         ...
      } catch (Exception e) {
         fail(ConnectorTestUtils.getStackTrace(e));
      }
   }
}
----

=== Test Resources
. *AutomationSpringBeans.xml* contains the maps and POJOs required by the tests to run.
. *automation-test-flows.xml* is a collection of flows, each containing a connector operation, that invoke on the tests.
. *automation-credentials.properties* stores the connector credentials and authenticated user related information.

=== Test Runners
Run different sets of tests with the aid of runners. Test cases are classified into two categories:

. *Smoke*: Tests that verify operations used on @Before and @After methods, thus assuring that it makes sense to run a test suite.
. *Regression*: Positive test on the operation attributes that you pass from a Message.

== Suite Implementation
---
=== Test Development Environment Set Up
After building a connector, add *target/generated-sources/mule* to the project build path. You may need to add other generated sources to the build path depending on the connector (such as target/generated-sources/cxf).

If a connector is *Standard*, add a *muleLicenseKey.lic* to the *src/test/resources* folder and remove it prior to committing your changes.

=== Packages and Files
. *org.mule.modules.<connector-project>.automation* contains the *<Connector>TestParent* and the _SmokeTests_ and _RegressionTests_ categories interfaces.
. *org.mule.modules.<connector-project>.automation.testrunners* contains the runners (RegressionTestSuite, SmokeTestSuite).
. *org.mule.modules.<connector-project>.automation.testcases* contains the functional test cases exclusively.
. *<connector-project>/src/test/resources* contains automation flows, credentials and Spring beans files:
.. *AutomationSpringBeans.xml*
.. *automation-test-flows.xml*
.. *automation-credentials.properties*

=== Automation Flows

For each operation, place a maximum of two flows in the *automation-test-flows* file. One flow is for mandatory attributes. This ensures that you implement all mandatory arguments in a connector and if applicable, use another flow with all attributes (mandatory and optional), to build a more general case for the operation.

=== automation-test-flows.xml and Operation Attributes

Each operation in the connector has at least a corresponding flow in the automation-test-flows file. The flow and its associated operation should be thought of as resources that can be called from multiple tests. Flow names are the same as the operation they contain or at least start with the name of the operation they contain, for example:

[source,xml]
----
<flow name="<operation-name>" doc:name="<operation-name>">
  <marketo:<operation-name>
    config-ref="<ConfigName>"
    doc:name="<operation-name>"  … />
</flow>

<flow name="<operation-name>-<particular-case>" doc:name="<operation-name>">
  <marketo:<operation-name>
    particularCaseAttribute="#[flowVars.attributeName]"
    config-ref="<ConfigName>"
    doc:name="<operation-name>"  … />
</flow>
----

Populate operation attributes as:

[source,xml]
attributeName="#[flowVars.attributeName]"

Or as:

[source,xml]
<taleo:<entityName> ref="#[flowVars.<entityName>Ref]"/>

In the case of being given the choice of passing non-primitive types (e.g. POJOs, List<POJOs>, Map<POJOs>, etc.) either from the payload, by reference, or by manually creating it using Anypoint Studio, either taking the value from the payload or by reference should be selected.

[source,xml]
----
<!-- mobjects value passed by as reference -->
<flow name="sync-mobjects" doc:name="sync-mobjects">
  <marketo:sync-mobjects config-ref="Marketo"
     doc:name="Sync MObjects"
     operation="#[flowVars.operation]"
     type="#[flowVars.type]">
    <marketo:mobjects ref="#[flowVars.mobjectsRef]"/>
  </marketo:sync-mobjects>
</flow>
----

Or

[source,xml]
----
<!-- mobject value taken from payload -->
<flow name="sync-mobjects" doc:name="sync-mobjects">
  <marketo:sync-mobjects config-ref="Marketo"
     doc:name="Sync MObjects"
     operation="#[flowVars.operation]"
     type="#[flowVars.type]"/>
</flow>
----

=== Keeping Headers Updated
Change the connector version to current to avoid breaking the configuration XML file, for example,

from: `http://www.mulesoft.org/schema/mule/taleo/1.0-SNAPSHOT/mule-taleo.xsd`

To: `http://www.mulesoft.org/schema/mule/taleo/current/mule-taleo.xsd`

=== Credentials
* Choose connector credentials from the automation-credential.properties file during test development, or if tests are to be run from within Eclipse.
* Populate the config element field with placeholders using:
`configRefAttribute="${serviceName.configRefAttribute}"`

[source,xml]
----
<marketo:config name="Marketo"
  userId="${marketo.userId}"
  key="${marketo.key}"
  endpointUrl="${marketo.endpointUrl}"
  doc:name="Marketo">
  <marketo:connection-pooling-profile initialisationPolicy="INITIALISE_ONE"
     exhaustedAction="WHEN_EXHAUSTED_GROW"/>
</marketo:config>
----

* Create a Property placeholder that references automation-credentials.properties or add the following as an attribute to the Mule node:

`xmlns:context="http://www.springframework.org/schema/context"`

Or add this as one of its child nodes:

`<context:property-placeholder location="automation-credentials.properties" />`

* Prior to committing, change the location value to:

`<context:property-placeholder location="${<CONNECTOR_NAME>_CREDENTIALS}" />`

This lets you run the suites from the console or build plan by passing the URL where the automation-credentials.properties are stored.

=== Test Data Using Spring Beans
AutomationSpringBeans stores the test data required for each test to run.

The most common case is to have a <testMethod>TestData map containing all the primitive values or bean references for a specific test. For more complex cases, additional beans for the test may be required besides the main TestData map.

The approach is that each test has its set of dedicated test values, hence the convention. Reusing the same bean on different test results in them being coupled; if some specific data setup is desired for a particular test, changes might end up producing an unexpected behavior on others.

By convention all bean IDs related to an operation should begin with the operation name followed by the bean class. This avoids naming conflicts and makes clear which operation this bean uses.

[source,xml]
----
<!--  get-lead -->
<bean id="testGetLeadLeadKey" class="com.marketo.mktows.LeadKey">
   <property name="keyType">
      <util:constant static-field="com.marketo.mktows.LeadKeyRef.IDNUM" />
   </property>
</bean>

<util:map id="testGetLeadLeadRecord" scope="prototype">
   <entry key="City" value="city" />
   <entry key="Company" value="company_title" />
   <entry key="Country" value="country" />
   <entry key="FirstName" value="first_name" />
   <entry key="LastName" value="last_name" />
   <entry key="MobilePhone" value="cell_phone" />
   <entry key="Phone" value="work_phone" />
   <entry key="State" value="state" />
   <entry key="Title" value="job_title" />
</util:map>

<!--  testGetLead method TestData map -->
<util:map id="testGetLeadTestData" scope="prototype">
   <entry key="type" value="LeadRecord" />
</util:map>
----

. In spring use scope="prototype" (if applicable) to ensure values from previous tests (ids, etc) are not reused in the following tests.
. "TestData" map can be used to store expected results for a test in case the expected value relates to the data been passed to them.

[source,xml]
----
<util:map id="createBatchAttendeeListTestData"
      map-class="java.util.HashMap"
      key-type="java.lang.String" value-type="java.lang.Object"
      scope="prototype">
        <entry key="payloadContent" value-ref="attendeeBatch"/>
        <entry key="batchType" value="CREATE"/>
        <entry key="expectedRecordsSucceeded" value="2"/>
</util:map>
----

Then

[source,java]
----
@Test
public void testCreateBatchAttendeeList() {
       ...
 assertEquals(payload.getRecordsSucceeded(),
   getTestRunMessageValue("expectedRecordsSucceeded"));

}
----

=== Relevant Cases Derived From Data
. Attribute types or entity members that are non-primitive values (for example, an entity having a Date field or complex types).
. Wildcards or special characters on queries.
. Output entities, such as a list that contains different types of records.
. If a client operation has not merely been wrapped, exercise connector custom code through a more complex test data setup for the test. An example of this are methods that receive a data representation object and return a concrete instance.
Hint: Check the developer’s unit tests.

`ConcreteInstance fromMap(Map<String,Object> mapRepresentation)`

=== Fields with Unique Values
Dynamically generate entity fields that contain unique values to make the automation runs more robust. For example:

[source,xml]
----
<bean id="randomEmailAddress"
  class="org.mule.modules.tests.ConnectorTestUtils"
  factory-method="generateRandomEmailAddress" scope="prototype" />
----

=== Date Generation Common Cases

[source,xml]
----
<bean id="xmlGregorianCalendarDateInThePast"
  class="org.mule.modules.tests.ConnectorTestUtils"
  factory-method="generateXMLGregorianCalendarDateForYesterday"
  scope="prototype" />
----

=== User Related Data
Use the automation-credentials.properties files in conjunction with AutomationSpringBeans.xml to test user related operations.

==== automation-credentials.properties
```
taleo.username=username
taleo.password=password
taleo.companyCode=companyCode
taleo.userId=42
```

==== AutomationSpringBeans

[source,xml]
----
<bean class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer">
  <property name="location">
    <value>automation-credentials.properties</value>
  </property>
</bean>

<!-- search-user  -->
<util:map id="testSearchUserTestData" map-class="java.util.HashMap"
  key-type="java.lang.String" value-type="java.lang.Object" scope="prototype">
  <entry key="expectedUserId" value="${taleo.userId}" />
  <entry key="searchParams" value-ref="searchUserSearchParams" />
</util:map>
----

== Test Methods
---
=== Good Test Case Qualities
. Flexibility: All data setup changes (for example, entity type changes) can be performed from the Spring file without modifying the tests.
. Only runtime generated values should be handled in a test, everything else should be declared in the AutomationSpringBeans file.

[source,java]
----
DeleteRecord deleteUserRecordRequest = new DeleteRecord();
deleteUserRecordRequest.setSysId(userSysId);
upsertPayloadContentOnTestRunMessage(deleteUserRecordRequest);
runFlowAndGetPayload("delete-user-record");
----

. Extensibility: Test cases can be used for any amount of entities and also apply validations to any kind of output.
. @Test should not start with any kind of preparation prior to calling the operation under test. That should fall under the @Before method. Ideally a test should call the flow of the operation under test, assert the result, and, if applicable, set data required for the @After method.
. Assertions are applied to values on the responses, avoid using the assertNotNull assertion.
.. In case a message processor returns an object that can contains null field values, it is acceptable to perform an assertNotNull on the field followed by the functional assertion on the field. This avoids failures being logged as errors.
.. If a message processor has void as its return type and the payload was not used to pass data to it you can use this assertion:

[source,java]
----
org.mule.modules.tests.ConnectorTestUtils.assertNullPayload(Object)

GetResponse getResponse = runFlowAndGetPayload("get-user");
assertEquals(userSysId, getResponse.getSysId());
assertEquals(expectedName, getResponse.getName());
----

. If void is returned by the operation under test, auxiliary calls to other operations can be made to verify that changes took effect.
. As last resort, sets of void operations can be grouped by a test case that validates that no exception is returned by their usage.

=== Test Fixture and tearDown
Request test data and perform use case preparation logic on the @Before methods. A @Test method should contain if possible, only a single flow call (the one that relates to the operation under test) and the assertions on its payload. On the @After method, revert the changes to the sandbox.
The frameworks enforces:
. Data consumed by the operation under test must be taken from the TestRunMessage. This implies that the TestRunMessage is initialized at some point prior to the invocation of the flow containing the operation.
. Additional flows can be invoked without altering the TestRunMessage by using:
.. runFlowAndGetMessage(String flowName, String beanId)
.. runFlowAndGetPayload(String flowName, String beanId)
. Runtime values can be added to the TestRunMessage to prepare the data for the operation under test.

[source,java]
----
 @Before
   public void setUp() throws Exception {
      HashMap<String, Object>
        leadRecord = getBeanFromContext("listOperationMObject");
      initializeTestRunMessage(leadRecord);
      // allows updating leadRecord with values from operation responses
      ...
   }
----

. "Operation under test" test data needs to be composed from setUp responses.

=== Errors and Failures
Fixture and tearDown throw Exception so that unexpected errors on their logic or calls are listed as an errors on the test and not as a failure.

[source,java]
----
   @Before
   public void setUp() throws Exception {
      // setUp logic
   }

   @Test
   public void setUp() throws Exception {
      // setUp logic
   }
----

If an exception is thrown on the @Test, the test is listed as failed.

[source,java]
----
   @Category({SmokeTests.class, RegressionTests.class})
   @Test
   public void test<operationName>() {
      try {
         ...
      } catch (Exception e) {
         fail(ConnectorTestUtils.getStackTrace(e));
      }
   }
----

== Test Cases Classification
---
Tests are categorized using @Category annotation on top of the test method signatures.

[source,java]
----
@Category({SmokeTests.class, RegressionTests.class})
@Test
----

Tests for operations that are used on the @Before or @After are to be marked as SmokeTests.

=== Test Runners
One for each test case type (SmokeTest, RegressionTest). Placed on the org.mule.modules.<connector>.automation.

[source,java]
----
@RunWith(Categories.class)
@IncludeCategory(RegressionTests.class)

@SuiteClasses({
      // All <operation>TestCases classes within the automation.testcases package
      AppendTestCases.class,
      DeleteDirectoryTestCases.class,
      ...
   })

public class RegressionTestSuite {

}
----

== DataSense (Dynamic metadata)
---

First of all create the DataSenseTestCases class on the connector functional test suite package

=== @MetaDataKeyRetriever method

. Add a testGetMetaDataKeys() method
. In the AutomationSpringBeans create a map bean containing the data for the getMetadata() test methods method.
.* It should contain the number of keys associated with the sandbox (expectedMetaDataKeysCount)
.* A list of maps whose fields follow the MetaDataKey format and represent MetaDataKeys for entities identified as critical.

[source,xml]
----
<util:map id="getMetaDataKeysTestData" map-class="java.util.HashMap" key-type="java.lang.String"
          value-type="java.lang.Object" scope="prototype">
    <entry key="expectedMetaDataKeysCount" value="10"/>
    <entry key="expectedMetaDataKeys">
        <list value-type="java.util.HashMap">
          <map key-type="java.lang.String" value-type="java.lang.Object">
              <entry key="displayName" value="CI_POSITION_DATA#Find"/>
              <entry key="id" value="CI_POSITION_DATA#Find"/>
              <entry key="category" value="InvokeCategory"/>
          </map>
          <map key-type="java.lang.String" value-type="java.lang.Object">
              <entry key="displayName" value="CI_POSITION_DATA#Create"/>
              <entry key="id" value="CI_PERSONAL_DATA#Create"/>
              <entry key="category" value="InvokeCategory"/>
          </map>
       </list>
    </entry>
</util:map>
----

. To the DataSenseTestCases class add the following test cases

[source,java]
----
@Before
public void setUp() throws Exception {
    initializeTestRunMessage("getMetaDataKeysTestData");
}

@Test
@Category({RegressionTests.class, SmokeTests.class})
public void testGetMetaDataKeysSuccess() {
  assertGetMetaDataKeysSuccess("PeopleSoft");
}

@Test
@Category({RegressionTests.class, SmokeTests.class})
public void testGetMetaDataKeysAmount() {
  List<MetaDataKey> retrievedMetadataKeys = getMetaDataKeyList("PeopleSoft");
    assertEquals(retrievedMetadataKeys.size(), Integer.parseInt((String) getTestRunMessageValue("expectedMetaDataKeysCount")));
}

@Test
@Category({RegressionTests.class, SmokeTests.class})
public void testGetMetaDataKeysContainsKeys() {
    assertMetaDataKeysContainsKeys("PeopleSoft", (List<HashMap<String, String>>) getTestRunMessageValue("expectedMetaDataKeys"));
}
----

If additional testing wants to be performed mule-connector-case provides a set of methods for MetaData testing.
* assertGetMetaDataKeysSuccess
* getMetaDataKeyList
* assertMetaDataKeysContainsKeys


=== @MetaDataRetriever method

==== Test getMetaData entity retrieval for all MetaDataKeys

. Add a Timeout rule on the DataSenseTestCases class to avoid the testGetMetaData from not completing its execution
. Add a testGetMetadata() method to the DataSenseTestCases class

[source,java]
----
@Rule
public Timeout globalTimeout = new Timeout(360000);

@Test
public void testGetMetaData() {
  List<MetaDataKey> metaDataKeys = getMetaDataKeyList("Salesforce");
  Iterator<MetaDataKey> iterator = metaDataKeys.iterator();

  while (iterator.hasNext()) {
    MetaDataKey metaDataKey = iterator.next();
    Result<MetaData> metaData = connector.getMetaData(metaDataKey);
    assertTrue(Result.Status.SUCCESS.equals(metaData.getStatus()));
  }

}
----

==== Test getMetaData method logic for a given entity

Add a GetMetaDataTestCases test class for all test related to input and output MetaData for target processors and entities.

To check the MetaData model implemented on the connector select an entity that exercises it.

First you'll need to define the method/entity under test and add it to your automation-test-flows.xml file

[source,xml]
----
<flow name="get-metadata-find" >
    <peoplesoft:invoke-operation type="CI_POSITION_DATA#Find" config-ref="PeopleSoft" doc:name="PeopleSoft">
        <peoplesoft:params/>
    </peoplesoft:invoke-operation>
</flow>
----

Using getOutputMetaDataPayload retrieve the MetaDataModel and cast it in order to check how the entities are described

[source,java]
----
    @Test
    @Category({RegressionTests.class, SmokeTests.class})
    public void testGetMetaDataCI_POSITION_DATAType() {
        try {
            MetaDataModel payload = getOutputMetaDataPayload("get-metadata-find");
            DefinedMapMetaDataModel definedMapMetaDataModel = (DefinedMapMetaDataModel) ((ListMetaDataModel) payload).getElementModel();
            List<MetaDataField> fields = definedMapMetaDataModel.getFields();
            assertEquals(7, fields.size());
        } catch (Exception e) {
            fail(ConnectorTestUtils.getStackTrace(e));
        }
    }

----

=== Grouping Types

For the testGetMetaDataKeysContainsKeys() test select entities that would have different category fields values because of their @MetaDataCategory class origin.

[source,xml]
----
<list value-type="java.util.HashMap">
  <map key-type="java.lang.String" value-type="java.lang.Object">
      <entry key="displayName" value="Account"/>
      <entry key="id" value="AccountId"/>
      <entry key="category" value="CategoryA"/>
  </map>
  <map key-type="java.lang.String" value-type="java.lang.Object">
      <entry key="displayName" value="Account"/>
      <entry key="id" value="AccountId"/>
      <entry key="category" value="CategoryB"/>
  </map>
</list>
----

Besides take one processor as representative of each @MetaDataCategory class (check their @MetaDataScope attribute value for that) and test their MetaData input and output behaviour by selecting the most representative entity.

[source,java]
----
    @Processor
    @MetaDataScope(InvokeCategory.class)
    public List<Map<String, Object>> invokeOperation(@MetaDataKeyParam String type, @Default("#[payload]") Map<String, Object> params) {
----

[source,xml]
----
<flow name="get-meta-data-get" >
    <peoplesoft:invoke-operation type="CI_POSITION_DATA#Get" config-ref="PeopleSoft" doc:name="PeopleSoft">
        <peoplesoft:params/>
    </peoplesoft:invoke-operation>
</flow>
----

[source,java]
----
@Test
@Category({RegressionTests.class, SmokeTests.class})
public void testGetProcessorIsMetaDataEnabled() {
  assertIsMetaDataEnabled("get-meta-data-get");
}

@Test
@Category({RegressionTests.class, SmokeTests.class})
public void testGetMetaDataGetInputMetaData() {
  try {
    assertFirstLevelInputMetaDataSuccess("get-meta-data-get", DataType.MAP);
  } catch (Exception e) {
    fail(ConnectorTestUtils.getStackTrace(e));
  }
}

@Test
@Category({RegressionTests.class, SmokeTests.class})
public void testGetMetaDataGetOutputMetaData() {
  try {
    assertListFirstLevelOutputMetaDataSuccess("get-meta-data-get", DataType.MAP.toString());
  } catch (Exception e) {
    fail(ConnectorTestUtils.getStackTrace(e));
  }
}
----

=== MetaDataOutputRetriever

In case that an @MetaDataOutputRetriever method is implemented test cases for it should be written with assertions on the input and output MetaData of the operations affected by its logic.

=== Input MetaData Negative cases
Logic added to handle requests to retrieve input MetaData passing an invalid type should be covered also on the GetMetaDataTestCases class.
Follow the approach of adding specific flows containing processors with an invalid type and requesting its input MetaData

Error message should relate to the connector domain.

== Test Connection
---

. Add the necessary config elements to support test configuration negative cases to the automation-test-flows.xml file. Config elements name convention is as follows: Test_Connection_Negative_<Particular_Case>. See an example below.

[source,xml]
----
<mongo:config name="Mongo_DB" username="${mongo.username}"
    password="${mongo.password}" host="${mongo.host}" port="${mongo.port}"
    database="${mongo.database}" doc:name="Mongo DB" connectionsPerHost="4"
    maxWaitTime="5000">
    <mongo:connection-pooling-profile
        maxActive="2" initialisationPolicy="INITIALISE_ONE" exhaustedAction="WHEN_EXHAUSTED_WAIT"
        maxWait="5000" />
</mongo:config>

<mongo:config name="Test_Connection_Negative_Invalid_Username" username="INVALID_USERNAME"
    password="${mongo.password}" host="${mongo.host}" port="${mongo.port}"
    database="${mongo.database}" doc:name="Mongo DB" connectionsPerHost="4"
    maxWaitTime="5000">
    <mongo:connection-pooling-profile
        maxActive="2" initialisationPolicy="INITIALISE_ONE" exhaustedAction="WHEN_EXHAUSTED_WAIT"
        maxWait="5000" />
</mongo:config>

 ...
----

. Create the ConnectTestCases class
. Add a positive and any necessary negative tests

[source,java]
----
import org.mule.common.Result;
import org.mule.common.TestResult;
import org.mule.common.Testable;

@Test
public void testConnectInvalidUsername() throws Exception {
    TestResult testResult =  getGlobalElementTestable("Test_Connection_Negative_Invalid_Username").test();
    assertEquals(Result.Status.FAILURE, testResult.getStatus());
    assertEquals("INVALID_CREDENTIALS", testResult.getFailureType().getName());
    assertEquals("Couldn't connect with the given credentials", testResult.getMessage());
}

@Test
public void testConnectSuccess() throws Exception {
    TestResult testResult =  ((Testable) getGlobalElementTestable("Mongo_DB")).test();
    assertEquals(Result.Status.SUCCESS, testResult.getStatus());
}
----

== Transformers
---

. For each transformer add a flow to the automation-test-flows.xml.

[source,xml]
----
<flow name="db-object-to-json-transformer">
    <mongo:dbobject-to-json doc:name="Mongo DB"/>
</flow>

----

. Create a TransformersTestCases class
. Call an operation that would return an object of the <typeFrom> type
. Insert that type on the payload
. Call the flow containing the transformer
. Cast or parse the returned to the <typeTo> class.
. No exceptions should be risen when tests are run.

[source,java]
----
@Test
public void testDbObjectToJSONTransformer() {

  GridFSInputFile operationPayload = null;

  try {

    File file = folder.newFile(getTestRunMessageValue("filename").toString());

    upsertOnTestRunMessage("filename", "filename");
    upsertOnTestRunMessage("metadataRef", new BasicDBObject());
    upsertOnTestRunMessage("payloadContent", file);

    operationPayload = runFlowAndGetPayload("create-file-from-payload");

    upsertOnTestRunMessage("payloadContent", operationPayload);

    Object json = JSON.parse((String) runFlowAndGetPayload("db-object-to-json-transformer"));

  } catch (Exception e) {
    fail(ConnectorTestUtils.getStackTrace(e));
  }

}
----

== Testing Inbound Endpoints (@Sources)
---
For now, inbound endpoint testing must be done by adding a http://www.mulesoft.org/documentation/display/current/VM+Transport+Reference[VM endpoint] in the flow that has the inbound endpoint we want to test. A VM endpoint is essentially an in-memory queue (hence the name VM, because they are handled by the JVM) addressable by a URL that stores messages until they are processed. By storing the messages received by the inbound endpoint in a VM queue, we can retrieve them in the test case and make assertions on them.

For example, if we want to test SQS’s Receive Messages operation, we need two flows: a flow that actually sends the message, and another flow with the Receive Messages inbound endpoint, as such:

[source,xml]
----
<flow name="send-message" doc:name="SendMessage">
   	<sqs:send-message config-ref="Sqs"
	message="#[flowVars.message]"
	queueUrl="#[flowVars.queueUrl]"/>
</flow>

<flow name="receive-message" doc:name="receive-message">
	<sqs:receive-messages config-ref="Sqs" queueUrl="#[flowVars.queueUrl]"/>
	...
</flow>
----

To actually get the messages to use in our test, we need to add a VM endpoint to the flow:

[source,xml]
----
<flow name="receive-message" doc:name="receive-message">
	<sqs:receive-messages config-ref="Sqs" queueUrl="#[flowVars.queueUrl]"/>
	<vm:outbound-endpoint path="receive"/>
</flow>
----

To use the VM endpoint, add this Maven dependency to your project's pom.xml file:

[source,xml]
----
<dependency>
<groupId>org.mule.transports</groupId>
<artifactId>mule-transport-vm</artifactId>
	<version>${mule.version}</version>
</dependency>
----

Update your XML schemas and namespaces as described in the http://www.mulesoft.org/documentation/display/current/VM+Transport+Reference[VM endpoint documentation].

Use (for now) the runFlowAndWaitForResponseVM method. The important thing to note here is the path of the queue. A simple test for these flows is:

[source,java]
----
public void testReceiveMessages() throws Exception {
    String message = “Hello world”;
    upsertOnTestRunMessage(“message”, message);
    String response = runFlowAndWaitForResponseVM(“send-message”, “receive”, 500L);
    assertEquals(message, response);
}
----

The parameters for runFlowAndWaitForResponseVM are as follows:
. The flow to run.
. The VM queue to wait for messages on.
. How long to wait (in milliseconds) before timing out and throwing an exception.

This information can also be seen in the JavaDoc for this method.

This is a preliminary way to implement this functionality because ideally there should be no need to manually add endpoints to flows in order to test them. See https://www.google.com/url?q=https%3A%2F%2Fwww.mulesoft.org%2Fjira%2Fbrowse%2FCLDCONNECT-1472&sa=D&sntz=1&usg=AFQjCNEsSvDUicqmL7DHFD5Ch01mWqa4zg[CLDCONNECT-1472] for more information.

== Setting Up OAuth Authentication
---
Manually generate the accessToken and pass this along with the credentials to the service to run the test suite.

Let's use Facebook as example:

. Manually get the Access Token https://developers.facebook.com/tools/explorer[Graph API Explorer].
. Add accessToken property to the automation-credentials.

```
facebook.username=<usernameValue>
facebook.appId=<appIdValue>
facebook.appSecret=<appSecretValue>
facebook.domain=<domainValue>
facebook.localPort=<localPortValue>
facebook.remotePort=<remotePortValue>
facebook.path=<pathValue>
facebook.accessToken=<generatedAccessToken>
```

. Add FacebookConnectorOAuthState bean to AutomationSpringBeans.

[source,xml]
----
<bean
  class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer">
 <property name="location">
   <value>automation-credentials.properties</value>
 </property>
</bean>
<bean id="connectorOAuthState"
  class="org.mule.module.facebook.oauth.FacebookConnectorOAuthState" >
  <property name="accessToken" value="${facebook.accessToken}" />
</bean>
----

. In <connectorName>TestParent, after initializing the muleContext, add a FacebookConnectorOAuthState instance to the Object Store.

[source,java]
----
@Before
    public void init() throws ObjectStoreException {
    ObjectStore objectStore = muleContext.getRegistry().lookupObject(MuleProperties.DEFAULT_USER_OBJECT_STORE_NAME);
    objectStore.store("accessTokenId", (FacebookConnectorOAuthState) context.getBean("connectorOAuthState"));
  }
----

. Add accessTokenId="accessTokenId" to the operations on automation-test-flows. The ObjectStore resolves this value.

[source,xml]
----
<facebook:config-with-oauth name="Facebook" appId="${facebook.appId}"
  appSecret="${facebook.appSecret}" doc:name="Facebook">
<facebook:oauth-callback-config domain="${facebook.domain}"
  localPort="${facebook.localPort}" remotePort="${facebook.remotePort}"
  path="${facebook.path}"/>
</facebook:config-with-oauth>

<flow name="get-user" doc:name="get-user">
  <facebook:get-user config-ref="Facebook" user="#[flowVars.username]"
    accessTokenId="accessTokenId" doc:name="Facebook" />
</flow>

----

=== Running the Suites
From the console:

```
export SALESFORCE_CREDENTIALS=http://172.16.20.35/automation/salesforce/automation-credentials.mvnproperties
mvn -Dtest=SmokeTestSuite test
mvn -Dtest=GetDailyTrendsTestCases#testGetDailyTrendsParametrized test
```

Or:
```
mvn -Dtest=SmokeTestSuite -Dmule.test.timeoutSecs=180 -DSALESFORCE_CREDENTIALS=http://172.16.20.35/automation/salesforce/automation-credentials.properties test
```

== Appendix

https://github.com/mulesoft/connector-certification-docs/blob/docs/current/attachments/automated%20funcional%20testing/appendixA.adoc[Appendix A: Debugging]
